<!--elice_3_34.html-->
<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>elcie_3_34.html</title>
</head>
<body>
<div class="instruction-content" data-reactid=".0.3.0.0.0.1.$0.0.0"><h2 id="advancedkmeansvsdbscan2">Advanced: K-Means vs. DBScan (2)</h2>

<p>앞선 과제에서 K-means 알고리즘의 문제점을 살펴보았습니다.
이번 과제에서는 이를 극복하는 또 다른 클러스터링 알고리즘인 DBSCAN에 대해서 살펴보겠습니다.
해당 알고리즘은 K-means와 달리 클러스터의 중앙점을 설정하지 않습니다.
대신, 가까이에 있는 데이터들을 하나의 클러스터로 인식합니다.
이러한 아이디어에 기반한 알고리즘으로 DBSCAN은 여러 장점을 가지고 있습니다.
먼저, 클러스터의 개수를 미리 정하지 않아도 됩니다.
또한, 여러 모형의 클러스터를 찾아낼 수 있는 장점이 있습니다.</p>

<p>자세한 설명은 아래의 문서를 참고 바랍니다.</p>

<ul>
<li>https://en.wikipedia.org/wiki/DBSCAN</li>
<li>https://algorithmicthoughts.wordpress.com/2013/05/29/machine-learning-dbscan/</li>
<li>http://blog.daum.net/wh1988ha/95</li>
<li>https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf</li>
</ul>

<p>DBSCAN 알고리즘을 사용하기 위해 역시 scikit-learn의 DBSCAN 함수를 사용하겠습니다.</p>

<p>#### sklearn.cluster.DBSCAN</p>

<p>DBSCAN 알고리즘은 scikit-learn 에 이미 구현된 DBSCAN 함수를 사용해서 쉽게 사용할 수 있습니다.
 이제 다음 예제를 통해 사용법을 알아보겠습니다.
 간단한 예제로 2차원에 있는 점 60 개를 클러스터로 나누어 보겠습니다.</p>

<pre><code>import numpy as np
import sklearn.cluster

np.random.seed(108)

points = np.random.random_sample([30, 2]) * 0.5
points2 = np.random.random_sample([30, 2]) * 0.5 + 1.5

classifier = sklearn.cluster.DBSCAN(eps=0.2)
classifier.fit(np.concatenate((points, points2)))
print(classifier.labels_)
</code></pre>

<p>결과는</p>

<pre><code>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
</code></pre>

<p>즉, 첫번째로 생성된 점들은 0번째 클러스터이고 두번째로 생성된 점들은 1번째 클러스터임을 의미합니다.
<code>eps</code> 파라메터는 두 점이 같은 이웃에 있다고 결정되어지는 최대 거리를 뜻합니다.</p>

<h2 id="">과제</h2>

<p>이번 과제에서는 앞서 살펴본 데이터에서 클러스터 찾는 문제를 K-means와 DBSCAN 알고리즘을 통해 풀어보겠습니다.
이를 통해 해당 알고리즘의 차이점을 살펴보겠습니다.</p>

<ol>
<li>Pandas를 이용하여 두 개의 데이터를 읽습니다.
<code>noisy_circles</code>은 <code>noisy_circle.csv</code> 파일에, <code>blobs</code>는 <code>blobs.csv</code> 파일에 저장되어 있습니다.
해당 파일을 Pandas의 <code>pd.read_csv()</code> 함수를 이용해 파일을 읽어들여 데이터 프레임으로 저장할 수 있습니다.</li>
<li>읽어들인 데이터에 대해 K-means 알고리즘을 실행합니다.
K-means의 클러스터 개수는 <code>run_kmeans</code> 함수의 파라메터인 <code>num_clusters</code> 값을 전달합니다.
마지막으로 K-means 알고리즘의 결과를 반환합니다.
위 예제에서 <code>classifier</code>에 해당합니다.</li>
<li>읽어들인 데이터에 대해 DBSCAN 알고리즘을 실행합니다.
두 점이 같은 이웃에 있을 거리인 eps를 <code>0.2</code>로 지정하며, 이를 eps 파라메터로 받습니다.
마지막으로 DBSCAN 알고리즘의 결과를 반환합니다.
위 예제에서 <code>classifier</code>에 해당합니다.</li>
<li>K-means와 DBSCAN를 실행할 데이터를 데이터 프레임에서 추출합니다.
제공되는 데이터 프레임은 첫 번째 열에는 각 데이터의 클래스 정보가 있습니다.
두, 세번째 열에는 각 점의 X축과 Y축 값이 적혀 있습니다.
<ul>
<li>데이터셋의 클래스 정보를 <code>y</code> 변수에 저장합니다.</li>
<li>데이터셋의 각각 데이터 포인트의 위치, 즉 [1, 2] 번째 인덱스에 있는 (x, y) 값들을 <code>X</code> 변수에 저장합니다. 이 (x, y) 값들은 run_kmeans 에 넘겨지게 됩니다.</li></ul></li>
</ol>

<h3 id="-1">입력</h3>

<h4 id="-2">데이터 프레임 일부</h4>

<pre><code>[[ 0.         -1.43415665  0.94938196]
 [ 1.          0.33341044  0.7531304 ]
 [ 1.          0.54022162  0.57801316]
 ...,
 [ 1.         -0.58410983 -0.66764867]
 [ 0.         -1.60622418 -0.76231783]
 [ 0.         -0.64604726 -1.45921285]]
</code></pre></div>
</body>
</html>